{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1vanl0pez/DataScienceSantiagoIvan/blob/streamLit/DSPRO1_HRAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6zoS2kb_zpvr",
        "outputId": "d3c912f4-8aff-4fbc-d61a-6b281e731a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/general_data.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Save dataframe as a CSV to make it easier to load in the Streamlit script\n",
        "df.to_csv('/content/general_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "kYIGWTg42obu",
        "outputId": "b8eb3629-24b0-47af-f640-f448bf2653e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Cargar datos desde el archivo CSV guardado\n",
        "file_path = '/content/general_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Paso de limpieza de datos\n",
        "columns_with_na = df.columns[df.isnull().sum() > 0].tolist()\n",
        "for col in columns_with_na:\n",
        "    median_value = df[col].median()\n",
        "    df.fillna({col: median_value}, inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Función para realizar la validación cruzada con k fold y registrar la importancia de las características\n",
        "def calculate_feature_importances(X, y):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
        "    fold_importances = []\n",
        "    fold_errors = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=24)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        fold_errors.append(mean_squared_error(y_test, y_pred))\n",
        "        fold_importances.append(model.feature_importances_)\n",
        "    avg_importances = np.mean(fold_importances, axis=0)\n",
        "    avg_error = np.mean(fold_errors)\n",
        "    return avg_importances, avg_error\n",
        "\n",
        "def calculate_adjustments(model, X, y, step=0.1):\n",
        "    adjustments = []\n",
        "    base_prediction = model.predict(X)\n",
        "    for feature in X.columns:\n",
        "        X_modified = X.copy()\n",
        "        X_modified[feature] += step\n",
        "        increased_prediction = model.predict(X_modified)\n",
        "        impact_per_unit = (increased_prediction - base_prediction).mean() / step\n",
        "        correlation = X[feature].corr(y)\n",
        "        direction = \"Increase\" if correlation > 0 else \"Decrease\"\n",
        "        adjustments.append({\n",
        "            \"Feature\": feature,\n",
        "            \"Impact per unit\": impact_per_unit,\n",
        "            \"Suggested change\": direction\n",
        "        })\n",
        "    adjustment_df = pd.DataFrame(adjustments).sort_values(by=\"Impact per unit\", ascending=False)\n",
        "    return adjustment_df\n",
        "\n",
        "def suggest_optimized_adjustments(input_data, model, step=0.5, target_increase=0.5, max_satisfaction=4.0, max_iterations=500):\n",
        "    base_prediction = model.predict(pd.DataFrame(input_data, columns=top_5_features.columns))[0]\n",
        "    target_prediction = min(base_prediction + target_increase, max_satisfaction)\n",
        "    adjusted_data = input_data.copy()\n",
        "    correlations = {feature: data_stayed[feature].corr(data_stayed[\"JobSatisfaction\"]) for feature in top_5_features}\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        total_adjustments = []\n",
        "        adjustments_applied = False\n",
        "        for idx, feature in enumerate(top_5_features):\n",
        "            if feature == \"MonthlyIncome\":\n",
        "                percent_salary_hike_index = top_5_features.columns.get_loc(\"PercentSalaryHike\")\n",
        "                if adjusted_data[0, percent_salary_hike_index] > 30 and all(adjusted_data[0, i] <= 0 for i in range(len(top_5_features)) if top_5_features[i] != \"MonthlyIncome\"):\n",
        "                    adjusted_data[0, idx] += 100\n",
        "                    new_prediction = model.predict(pd.DataFrame(adjusted_data, columns=top_5_features))[0]\n",
        "                    if new_prediction >= target_prediction:\n",
        "                        return {\n",
        "                            \"Adjusted Inputs\": dict(zip(top_5_features, adjusted_data[0])),\n",
        "                            \"New Prediction\": new_prediction,\n",
        "                            \"Iterations\": iteration + 1\n",
        "                        }\n",
        "                    adjustments_applied = True\n",
        "                    continue\n",
        "            input_modified = adjusted_data.copy()\n",
        "            relationship_direction = 1 if correlations[feature] > 0 else -1\n",
        "            proposed_value = adjusted_data[0, idx] + step * relationship_direction\n",
        "            if proposed_value <= 0:\n",
        "                continue\n",
        "            if feature == \"PercentSalaryHike\" and proposed_value > 30:\n",
        "                continue\n",
        "            input_modified[0, idx] = proposed_value\n",
        "            new_prediction = model.predict(pd.DataFrame(input_modified, columns=top_5_features.columns))[0]\n",
        "            impact_per_unit = (new_prediction - base_prediction) / step\n",
        "            if abs(impact_per_unit) > 0:\n",
        "                adjustment_step = step * relationship_direction\n",
        "                total_adjustments.append((idx, adjustment_step, impact_per_unit))\n",
        "                adjustments_applied = True\n",
        "\n",
        "        for idx, adjustment_step, _ in total_adjustments:\n",
        "            adjusted_data[0, idx] += adjustment_step\n",
        "\n",
        "        new_prediction = model.predict(pd.DataFrame(adjusted_data, columns=top_5_features.columns))[0]\n",
        "        if new_prediction >= target_prediction:\n",
        "            return {\n",
        "                \"Adjusted Inputs\": dict(zip(top_5_features.columns, adjusted_data[0])),\n",
        "                \"New Prediction\": new_prediction,\n",
        "                \"Iterations\": iteration + 1\n",
        "            }\n",
        "        if not adjustments_applied:\n",
        "            return {\n",
        "                \"Message\": \"No further optimization possible while maintaining positive values.\",\n",
        "                \"Adjusted Inputs\": dict(zip(top_5_features, adjusted_data[0])),\n",
        "                \"Final Prediction\": new_prediction\n",
        "            }\n",
        "    return {\n",
        "        \"Message\": \"Max iterations reached without achieving target increase.\",\n",
        "        \"Adjusted Inputs\": dict(zip(top_5_features.columns, adjusted_data[0])),\n",
        "        \"Final Prediction\": new_prediction\n",
        "    }\n",
        "\n",
        "# Definir características y pasos de entrenamiento del modelo\n",
        "data_stayed = df[df['Attrition_Yes'] == 0]\n",
        "X_stayed = data_stayed.drop(columns=[\"JobSatisfaction\"])\n",
        "y_stayed = data_stayed[\"JobSatisfaction\"]\n",
        "\n",
        "top_5_features = X_stayed[[\"MonthlyIncome\", \"DistanceFromHome\", \"PercentSalaryHike\",\n",
        "                           \"YearsSinceLastPromotion\", \"TrainingTimesLastYear\"]]\n",
        "X_important_stayed = data_stayed[top_5_features.columns]\n",
        "\n",
        "final_model = RandomForestRegressor(n_estimators=100, random_state=24)\n",
        "final_model.fit(X_important_stayed, y_stayed)\n",
        "\n",
        "# Interfaz de Streamlit\n",
        "st.title(\"Job Satisfaction Prediction App\")\n",
        "st.write(\"## Enter the following data to determine job satisfaction:\")\n",
        "\n",
        "input_data = []\n",
        "for feature in top_5_features.columns:\n",
        "    value = st.number_input(feature, min_value=0.0)\n",
        "    input_data.append(value)\n",
        "\n",
        "input_data = np.array([input_data])\n",
        "\n",
        "if st.button('Predict Satisfaction'):\n",
        "    satisfaction_prediction = final_model.predict(pd.DataFrame(input_data, columns=top_5_features.columns))[0]\n",
        "\n",
        "    if satisfaction_prediction <= 2:\n",
        "        traffic_light = \"Red\"\n",
        "    elif 2 < satisfaction_prediction <= 3:\n",
        "        traffic_light = \"Yellow\"\n",
        "    else:\n",
        "        traffic_light = \"Green\"\n",
        "\n",
        "    st.write(f\"Predicted Satisfaction: {satisfaction_prediction:.2f}\")\n",
        "    st.write(f\"Traffic Light Scale: {traffic_light}\")\n",
        "\n",
        "    if traffic_light != \"Green\":\n",
        "        st.write(\"Optimizing adjustments to improve satisfaction...\")\n",
        "        optimization_result = suggest_optimized_adjustments(input_data, final_model, step=0.5, target_increase=0.5, max_satisfaction=4.0)\n",
        "        st.write(\"Optimization Results:\")\n",
        "        for key, value in optimization_result.items():\n",
        "            st.write(f\"{key}: {value}\")\n",
        "    else:\n",
        "        st.write(\"Satisfaction is already at green level. No adjustments needed.\")\n",
        "\n",
        "st.write(\"### Relevant Features Range for Job Satisfaction:\")\n",
        "for feature in top_5_features.columns:\n",
        "    min_val = data_stayed[feature].min()\n",
        "    max_val = data_stayed[feature].max()\n",
        "    mean_val = data_stayed[feature].mean()\n",
        "    st.write(f\"{feature} - Min: {min_val}, Max: {max_val}, Avg: {mean_val:.2f}\")\n"
      ],
      "metadata": {
        "id": "zaefG_qx4H_k",
        "outputId": "f415bd50-30bb-4cd5-f85d-d1f6630c1ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2pWW0XfbvaktveDe8yiGGwsULY4_2ruivCyVZmVyQYPSEPGrQ\n"
      ],
      "metadata": {
        "id": "icMgkgwJ1OoE",
        "outputId": "275c92e6-363a-4798-e95f-0f30955f78bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!killall ngrok\n"
      ],
      "metadata": {
        "id": "oFX8JHLw4ddq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Connect to port 8501 and specify the tunnel type\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app URL: {public_url}\")\n"
      ],
      "metadata": {
        "id": "ecJJucq90NP8",
        "outputId": "d4f5d97f-ac5d-4925-ecbc-aae2de9fc982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app URL: NgrokTunnel: \"https://9188-34-169-61-194.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&\n",
        "\n"
      ],
      "metadata": {
        "id": "bwhVllcE2BUp"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}