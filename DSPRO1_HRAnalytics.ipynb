{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1vanl0pez/DataScienceSantiagoIvan/blob/streamLit/DSPRO1_HRAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n",
        "!pip install millify"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6zoS2kb_zpvr",
        "outputId": "a96c9593-631f-44c7-d5fe-f82fb353c82f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.2 streamlit-1.41.1 watchdog-6.0.0\n",
            "Collecting millify\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: millify\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1845 sha256=fc032786af8a459fcdfee6a33cadd968b81e1092164fcff42452c61aaa315e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/8f/53/2759feac2e247ce89c1165c3ff12d484de7714a875ea3464f0\n",
            "Successfully built millify\n",
            "Installing collected packages: millify\n",
            "Successfully installed millify-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# Import libraries\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from millify import millify\n",
        "\n",
        "# Read dataset\n",
        "#file_path = '/content/general_data.csv'\n",
        "#df = pd.read_csv(file_path)\n",
        "# Data cleaning\n",
        "def clean_data(df):\n",
        "  columns_with_na = df.columns[df.isnull().sum() > 0].tolist()\n",
        "  for col in columns_with_na:\n",
        "      median_value = df[col].median()\n",
        "      df.fillna({col: median_value}, inplace=True)\n",
        "  df = pd.get_dummies(df, drop_first=True)\n",
        "  return df\n",
        "# Function to optimize input variables\n",
        "def suggest_optimized_adjustments(input_data, model, target_increase=0.5, max_satisfaction=4.0, max_iterations=500, percent_adjustment=0.02):\n",
        "    base_prediction = model.predict(pd.DataFrame(input_data, columns=top_5_features.columns))[0]\n",
        "    target_prediction = min(base_prediction + target_increase, max_satisfaction)\n",
        "    adjusted_data = input_data.copy()\n",
        "    correlations = {feature: data_stayed[feature].corr(data_stayed[\"JobSatisfaction\"]) for feature in top_5_features}\n",
        "    for iteration in range(max_iterations):\n",
        "        total_adjustments = []\n",
        "        adjustments_applied = False\n",
        "        for idx, feature in enumerate(top_5_features):\n",
        "            if feature == \"MonthlyIncome\":\n",
        "                percent_salary_hike_index = top_5_features.columns.get_loc(\"PercentSalaryHike\")\n",
        "                if adjusted_data[0, percent_salary_hike_index] > 30 and all(adjusted_data[0, i] <= 0 for i in range(len(top_5_features)) if top_5_features[i] != \"MonthlyIncome\"):\n",
        "                    adjusted_data[0, idx] += 100\n",
        "                    new_prediction = model.predict(pd.DataFrame(adjusted_data, columns=top_5_features))[0]\n",
        "                    if new_prediction >= target_prediction:\n",
        "                        return {\n",
        "                            \"Adjusted Inputs\": dict(zip(top_5_features, adjusted_data[0])),\n",
        "                            \"New Prediction\": new_prediction,\n",
        "                            \"Iterations\": iteration + 1\n",
        "                        }\n",
        "                    adjustments_applied = True\n",
        "                    continue\n",
        "            input_modified = adjusted_data.copy()\n",
        "            relationship_direction = 1 if correlations[feature] > 0 else -1\n",
        "            proposed_value = adjusted_data[0, idx] * (1 + percent_adjustment * relationship_direction)\n",
        "            if proposed_value <= 0:\n",
        "                continue\n",
        "            if feature == \"PercentSalaryHike\" and proposed_value > 30:\n",
        "                continue\n",
        "            input_modified[0, idx] = proposed_value\n",
        "            new_prediction = model.predict(pd.DataFrame(input_modified, columns=top_5_features.columns))[0]\n",
        "            impact_per_unit = (new_prediction - base_prediction) / (adjusted_data[0, idx] * percent_adjustment)\n",
        "            if abs(impact_per_unit) > 0:\n",
        "                adjustment_step = proposed_value - adjusted_data[0, idx]\n",
        "                total_adjustments.append((idx, adjustment_step, impact_per_unit))\n",
        "                adjustments_applied = True\n",
        "\n",
        "        for idx, adjustment_step, _ in total_adjustments:\n",
        "            adjusted_data[0, idx] += adjustment_step\n",
        "\n",
        "        new_prediction = model.predict(pd.DataFrame(adjusted_data, columns=top_5_features.columns))[0]\n",
        "        if new_prediction >= target_prediction:\n",
        "            return {\n",
        "                \"Adjusted Inputs\": dict(zip(top_5_features.columns, adjusted_data[0])),\n",
        "                \"New Prediction\": new_prediction,\n",
        "                \"Iterations\": iteration + 1\n",
        "            }\n",
        "        if not adjustments_applied:\n",
        "            return {\n",
        "                \"Message\": \"No further optimization possible while maintaining positive values.\",\n",
        "                \"Adjusted Inputs\": dict(zip(top_5_features, adjusted_data[0])),\n",
        "                \"Final Prediction\": new_prediction\n",
        "            }\n",
        "    return {\n",
        "        \"Message\": \"Max iterations reached without achieving target increase.\",\n",
        "        \"Adjusted Inputs\": dict(zip(top_5_features.columns, adjusted_data[0])),\n",
        "        \"Final Prediction\": new_prediction\n",
        "    }\n",
        "\n",
        "# USER INTERFACE USING STREAMLIT\n",
        "# Title and logo using columns to improve distribution\n",
        "col1, col2 = st.columns([1, 3])\n",
        "with col1:\n",
        "    st.image(\"logo.png\", width=400)\n",
        "with col2:\n",
        "    st.title(\"Job Satisfaction Prediction App\")\n",
        "\n",
        "st.write(\"#### To start with the analysis, upload your data\")\n",
        "cols = st.columns(3)\n",
        "with cols[0]:\n",
        "    dataset = st.file_uploader(\"Choose a file\", type=[\"xlsx\"], accept_multiple_files=False)\n",
        "if dataset is not None:\n",
        "    df = pd.read_excel(dataset)\n",
        "    df.to_csv('/content/general_data.csv', index=False)\n",
        "    df = clean_data(df)\n",
        "    # Train the model with employees who stayed in the company\n",
        "    data_stayed = df[df['Attrition_Yes'] == 0]\n",
        "    X_stayed = data_stayed.drop(columns=[\"JobSatisfaction\"])\n",
        "    y_stayed = data_stayed[\"JobSatisfaction\"]\n",
        "    # Select the features to work with\n",
        "    top_5_features = X_stayed[[\"MonthlyIncome\", \"DistanceFromHome\", \"PercentSalaryHike\",\n",
        "                              \"YearsSinceLastPromotion\", \"TrainingTimesLastYear\"]]\n",
        "    X_important_stayed = data_stayed[top_5_features.columns]\n",
        "    # Data model: random forest regressor\n",
        "    final_model = RandomForestRegressor(n_estimators=100, max_depth=9, random_state=24)\n",
        "    final_model.fit(X_important_stayed, y_stayed)\n",
        "    # Subheader for feature ranges\n",
        "    # Horizontal separator\n",
        "    st.write(\"-\" * 500)\n",
        "    st.subheader(\"Features range:\")\n",
        "    cols = st.columns(3)  # Divide the UI into 3 columns\n",
        "    colors = [\"#0671e3\", \"#09bf04\", \"#e32406\"]  # Progress bar colors\n",
        "\n",
        "    # Display progress bars for the first three features\n",
        "    for i, feature in enumerate(top_5_features.columns[:3]):\n",
        "        min_val = data_stayed[feature].min()\n",
        "        max_val = data_stayed[feature].max()\n",
        "        mean_val = data_stayed[feature].mean()\n",
        "        # Normalize mean for progress bar\n",
        "        normalized_mean = (mean_val - min_val) / (max_val - min_val) * 100\n",
        "        color = colors[i]\n",
        "        # HTML for a styled progress bar\n",
        "        progress_bar_html = f\"\"\"\n",
        "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "            <div style=\"font-size: 18px; font-weight: bold; color: #a8b0b2; margin-bottom: px;\">{feature}</div>\n",
        "            <div style=\"width: 100%; background-color: #b3c8cb; border-radius: 25px; position: relative;\">\n",
        "                <div style=\"height: 20px; width: {normalized_mean}%; background-color: {color}; border-radius: 25px;\"></div>\n",
        "                <span style=\"position: absolute; left: 0%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb;\">{min_val}</span>\n",
        "                <span style=\"position: absolute; left: {normalized_mean}%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb; transform: translateX(-50%);\">{mean_val:.2f}</span>\n",
        "                <span style=\"position: absolute; right: 0%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb;\">{max_val}</span>\n",
        "            </div>\n",
        "        </div>\"\"\"\n",
        "        # Render the progress bar in the column\n",
        "        cols[i].markdown(progress_bar_html, unsafe_allow_html=True)\n",
        "\n",
        "    # Display progress bars for the last two features\n",
        "    cols2 = st.columns(4)\n",
        "    colors2 = [\"#e306a0\", \"#8b00ff\"]  # Progress bar colors\n",
        "    for i, feature in enumerate(top_5_features.columns[3:]):\n",
        "        min_val = data_stayed[feature].min()\n",
        "        max_val = data_stayed[feature].max()\n",
        "        mean_val = data_stayed[feature].mean()\n",
        "        normalized_mean = (mean_val - min_val) / (max_val - min_val) * 100\n",
        "        color = colors2[i]\n",
        "        progress_bar_html = f\"\"\"\n",
        "        <br>\n",
        "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "            <div style=\"font-size: 18px; font-weight: bold; color: #a8b0b2; margin-bottom: 5px;\">{feature}</div>\n",
        "            <div style=\"width: 100%; background-color: #b3c8cb; border-radius: 25px; position: relative;\">\n",
        "                <div style=\"height: 20px; width: {normalized_mean}%; background-color: {color}; border-radius: 25px;\"></div>\n",
        "                <span style=\"position: absolute; left: 0%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb;\">{min_val}</span>\n",
        "                <span style=\"position: absolute; left: {normalized_mean}%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb; transform: translateX(-50%);\">{mean_val:.2f}</span>\n",
        "                <span style=\"position: absolute; right: 0%; top: 25px; font-size: 18px; font-weight: bold; color: #b3c8cb;\">{max_val}</span>\n",
        "            </div>\n",
        "        </div>\"\"\"\n",
        "        # Render the progress bar in columns\n",
        "        cols2[i + 1].markdown(progress_bar_html, unsafe_allow_html=True)\n",
        "    # Horizontal separator\n",
        "    st.write(\"-\" * 500)\n",
        "\n",
        "    # Input fields for each feature\n",
        "    st.subheader(\"Enter the following data to compute job satisfaction:\")\n",
        "    input_data = []\n",
        "    # Use columns to improve distribution\n",
        "    col_inputs = st.columns(5)\n",
        "    for i, feature in enumerate(top_5_features.columns):\n",
        "        with col_inputs[i]:\n",
        "            value = st.number_input(feature, min_value=0.0)\n",
        "        input_data.append(value)\n",
        "    # Convert input to numpy array\n",
        "    input_data = np.array([input_data])\n",
        "\n",
        "    # Button to predict satisfaction\n",
        "    if st.button('Predict satisfaction'):\n",
        "        # Initial values for variables\n",
        "        st.session_state[\"satisfaction_prediction\"] = None\n",
        "        st.session_state[\"optimization_result\"] = None\n",
        "        st.session_state[\"prediction_made\"] = False\n",
        "\n",
        "        satisfaction_prediction = final_model.predict(pd.DataFrame(input_data, columns=top_5_features.columns))[0]\n",
        "        st.session_state[\"satisfaction_prediction\"] = satisfaction_prediction\n",
        "        st.session_state[\"prediction_made\"] = True\n",
        "\n",
        "    # Display prediction results when the prediction has been made\n",
        "    # .get (key, default value) -> returns the existing value, so if\n",
        "    # it's True, the code will be executed\n",
        "    if st.session_state.get(\"prediction_made\", False):\n",
        "        satisfaction_prediction = st.session_state[\"satisfaction_prediction\"]\n",
        "        # Select image to display based on the result\n",
        "        if satisfaction_prediction <= 2:\n",
        "            traffic_image = \"red.png\"\n",
        "        elif 2 < satisfaction_prediction <= 3:\n",
        "            traffic_image = \"yellow.png\"\n",
        "        else:\n",
        "            traffic_image = \"green.png\"\n",
        "        # Create columns to improve visual arrangement\n",
        "        cols = st.columns(4)\n",
        "        # Display predicted satisfaction using an HTML markdown\n",
        "        with cols[1]:\n",
        "            st.markdown(f\"\"\"\n",
        "                <div style=\"display: flex; align-items: center; justify-content: space-between; height: 135px; padding: 40px; border: 1px solid #ddd; border-radius: 10px; margin: 10px 0;\">\n",
        "                    <div style=\"text-align: center;\">\n",
        "                        <div style=\"font-size: 20px; font-weight: bold; color: #a8b0b2;\">Predicted satisfaction</div>\n",
        "                        <div style=\"font-size: 40px; font-weight: bold; color: #0671e3;\">{satisfaction_prediction:.2f}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "        # Display the traffic light image\n",
        "        with cols[2]:\n",
        "            st.image(traffic_image, width=75)\n",
        "\n",
        "        # Show optimization button if satisfaction is not green\n",
        "        if satisfaction_prediction > 3:\n",
        "            st.write(\"Satisfaction is already at green level. No adjustments needed.\")\n",
        "        else:\n",
        "            # Optimize input features\n",
        "            if st.button('Optimize results'):\n",
        "                optimization_result = suggest_optimized_adjustments(\n",
        "                    input_data, final_model, step=0.5, target_increase=0.5, max_satisfaction=4.0\n",
        "                )\n",
        "                st.session_state[\"optimization_result\"] = optimization_result\n",
        "\n",
        "    # Display optimization results if there are optimized values\n",
        "    if st.session_state.get(\"optimization_result\", None):\n",
        "        optimization_result = st.session_state[\"optimization_result\"]\n",
        "        # In case features were optimized compute delta with original ones\n",
        "        if \"Adjusted Inputs\" in optimization_result:\n",
        "            original_values = dict(zip(top_5_features.columns, input_data[0]))\n",
        "            adjusted_values = optimization_result[\"Adjusted Inputs\"]\n",
        "            final_prediction = optimization_result.get(\"New Prediction\", st.session_state[\"satisfaction_prediction\"])\n",
        "            iterations = optimization_result.get(\"Iterations\", 0)\n",
        "            prediction_delta = final_prediction - st.session_state[\"satisfaction_prediction\"]\n",
        "\n",
        "            #Display results in columns\n",
        "            st.subheader(\"Optimization results:\")\n",
        "            columns = st.columns(len(top_5_features.columns))  # Create columns for metrics\n",
        "            for idx, (feature, adjusted_value) in enumerate(adjusted_values.items()):\n",
        "                original_value = original_values[feature]\n",
        "                delta = adjusted_value - original_value\n",
        "                with columns[idx]:\n",
        "                    # Millify MonthlyIncome\n",
        "                    if feature == \"MonthlyIncome\":\n",
        "                        income = millify(adjusted_value, precision=5)\n",
        "                        st.metric(label=feature, value=income, delta=f\"{delta:.2f}\")\n",
        "                    else:\n",
        "                        st.metric(label=feature, value=f\"{adjusted_value:.2f}\", delta=f\"{delta:.2f}\")\n",
        "\n",
        "            # Display final prediction and iterations\n",
        "            if final_prediction <= 2:\n",
        "                traffic_image = \"red.png\"\n",
        "            elif 2 < final_prediction <= 3:\n",
        "                traffic_image = \"yellow.png\"\n",
        "            else:\n",
        "                traffic_image = \"green.png\"\n",
        "            colus = st.columns(4)\n",
        "            with colus[1]:\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div style=\"display: flex; align-items: center; justify-content: space-between; height: 135px; padding: 60px; border: 1px solid #ddd; border-radius: 10px; margin: 10px 0;\">\n",
        "                        <div style=\"text-align: center;\">\n",
        "                            <div style=\"font-size: 20px; font-weight: bold; color: #a8b0b2;\">Final satisfaction</div>\n",
        "                            <div style=\"font-size: 40px; font-weight: bold; color: #0671e3;\">{final_prediction:.2f}</div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "            with colus[2]:\n",
        "                st.image(traffic_image, width=75)\n",
        "            st.write(f\"Iterations taken for optimization: **{iterations}**\")"
      ],
      "metadata": {
        "id": "zaefG_qx4H_k",
        "outputId": "ce0ffbdb-8a08-4ca5-bbe8-d8a3b243d949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token authentification\n",
        "!ngrok authtoken 2pWW0XfbvaktveDe8yiGGwsULY4_2ruivCyVZmVyQYPSEPGrQ"
      ],
      "metadata": {
        "id": "icMgkgwJ1OoE",
        "outputId": "b062e78a-3d4b-406a-f027-97f17f015c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop all running processes\n",
        "!killall ngrok"
      ],
      "metadata": {
        "id": "oFX8JHLw4ddq",
        "outputId": "94b0b6dc-d3fc-4745-aa6e-00da43e5add3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-12-20T12:49:10+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-7cbea90d-e35f-4392-946e-597aa80fa6da acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create public URL\n",
        "from pyngrok import ngrok\n",
        "# Connect to port 8501 and specify the tunnel type\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app URL: {public_url}\")"
      ],
      "metadata": {
        "id": "ecJJucq90NP8",
        "outputId": "68902d8e-a98b-4ae4-9bf3-882d4ac6f587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app URL: NgrokTunnel: \"https://0a82-34-106-220-71.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run app\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "bwhVllcE2BUp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tD23SLhw5tgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}