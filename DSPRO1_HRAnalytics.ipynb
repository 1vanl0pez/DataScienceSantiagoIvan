{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1vanl0pez/DataScienceSantiagoIvan/blob/randomForestClassifier-v2/DSPRO1_HRAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set file path\n",
        "file_path = '/content/drive/MyDrive/general_data.xlsx'\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "df = pd.read_excel(file_path)  # Use read_excel to load the default sheet\n",
        "\n",
        "# Filter out rows where Attrition is \"Yes\"\n",
        "df_filtered = df[df['Attrition'] == 'No'].copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df_cleaned = df_filtered.drop(columns=['Unnamed: 25', 'Unnamed: 26'], errors='ignore')\n",
        "\n",
        "# Select necessary features and target variable\n",
        "features = ['MonthlyIncome', 'DistanceFromHome', 'TrainingTimesLastYear',\n",
        "            'PercentSalaryHike', 'YearsSinceLastPromotion']\n",
        "target = 'JobSatisfaction'\n",
        "\n",
        "# Ensure the selected features and target exist in the dataset\n",
        "df_cleaned = df_cleaned[features + [target]].dropna()\n",
        "\n",
        "# Encode the target variable to categorical integers\n",
        "df_cleaned[target] = df_cleaned[target].astype(int)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assume you already have your X_train and y_train ready\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Initialize RandomForestClassifier with random_state for reproducibility\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters and score\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Sample predictions\n",
        "predictions = best_rf.predict(X_test)\n",
        "print(\"Sample of Predictions:\")\n",
        "print(pd.DataFrame(predictions))\n",
        "\n",
        "# Feature importance analysis\n",
        "feature_importances = best_rf.feature_importances_\n",
        "feature_names = ['MonthlyIncome', 'DistanceFromHome', 'TrainingTimesLastYear', 'PercentSalaryHike', 'YearsSinceLastPromotion']\n",
        "\n",
        "# Create a DataFrame to display the feature importance\n",
        "importance_df = pd.DataFrame(list(zip(feature_names, feature_importances)), columns=['Feature', 'Importance'])\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(importance_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to predict job satisfaction and map it to traffic light system\n",
        "def predict_job_satisfaction(monthly_income, distance_from_home, trainings_last_year,\n",
        "                              percent_salary_hike, years_since_last_promotion):\n",
        "    input_data = pd.DataFrame([{\n",
        "        'MonthlyIncome': monthly_income,\n",
        "        'DistanceFromHome': distance_from_home,\n",
        "        'TrainingTimesLastYear': trainings_last_year,\n",
        "        'PercentSalaryHike': percent_salary_hike,\n",
        "        'YearsSinceLastPromotion': years_since_last_promotion\n",
        "    }])\n",
        "    prediction = model.predict(input_data)[0]  # Predict the satisfaction level (1-4)\n",
        "\n",
        "    # Map the prediction to traffic light system\n",
        "    if prediction >= 3:\n",
        "        return \"Green (Good)\"\n",
        "    elif prediction == 2:\n",
        "        return \"Yellow (Warning)\"\n",
        "    else:\n",
        "        return \"Red (Bad)\"\n",
        "\n",
        "# Interactive Input\n",
        "monthly_income = int(input(\"Enter Monthly Income: \"))\n",
        "distance_from_home = int(input(\"Enter Distance From Home (in km): \"))\n",
        "trainings_last_year = int(input(\"Enter Training Times Last Year: \"))\n",
        "percent_salary_hike = int(input(\"Enter Percent Salary Hike: \"))\n",
        "years_since_last_promotion = int(input(\"Enter Years Since Last Promotion: \"))\n",
        "\n",
        "# Get the prediction\n",
        "result = predict_job_satisfaction(monthly_income, distance_from_home,\n",
        "                                   trainings_last_year, percent_salary_hike,\n",
        "                                   years_since_last_promotion)\n",
        "print(f\"\\nPredicted Job Satisfaction: {result}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jnQ2WXZ6kpV2",
        "outputId": "5f530b84-7894-44d8-eef0-8d9e2fad8c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Cross-Validation Score: 0.9035318711525357\n",
            "Sample of Predictions:\n",
            "     0\n",
            "0    3\n",
            "1    4\n",
            "2    4\n",
            "3    4\n",
            "4    2\n",
            "..  ..\n",
            "731  1\n",
            "732  4\n",
            "733  4\n",
            "734  2\n",
            "735  3\n",
            "\n",
            "[736 rows x 1 columns]\n",
            "\n",
            "Feature Importance:\n",
            "                   Feature  Importance\n",
            "0            MonthlyIncome    0.363088\n",
            "1         DistanceFromHome    0.204377\n",
            "3        PercentSalaryHike    0.170348\n",
            "4  YearsSinceLastPromotion    0.139739\n",
            "2    TrainingTimesLastYear    0.122449\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d0eb0dfd0db3>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Interactive Input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mmonthly_income\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Monthly Income: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0mdistance_from_home\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Distance From Home (in km): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mtrainings_last_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Training Times Last Year: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set file path\n",
        "file_path = '/content/drive/MyDrive/general_data.xlsx'\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "df = pd.read_excel(file_path)  # Use read_excel to load the default sheet\n",
        "\n",
        "# Filter out rows where Attrition is \"Yes\"\n",
        "df_filtered = df[df['Attrition'] == 'No'].copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df_cleaned = df_filtered.drop(columns=['Unnamed: 25', 'Unnamed: 26'], errors='ignore')\n",
        "\n",
        "# Select necessary features and target variable\n",
        "features = ['MonthlyIncome', 'DistanceFromHome', 'TrainingTimesLastYear',\n",
        "            'PercentSalaryHike', 'YearsSinceLastPromotion']\n",
        "target = 'JobSatisfaction'\n",
        "\n",
        "# Ensure the selected features and target exist in the dataset\n",
        "df_cleaned = df_cleaned[features + [target]].dropna()\n",
        "\n",
        "# Encode the target variable to categorical integers\n",
        "df_cleaned[target] = df_cleaned[target].astype(int)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForest model\n",
        "best_rf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_leaf=1, min_samples_split=2, random_state=42)\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Determine the min and max for each feature to use in generating test data\n",
        "feature_ranges = {\n",
        "    'MonthlyIncome': (df['MonthlyIncome'].min(), df['MonthlyIncome'].max()),\n",
        "    'DistanceFromHome': (df['DistanceFromHome'].min(), df['DistanceFromHome'].max()),\n",
        "    'TrainingTimesLastYear': (df['TrainingTimesLastYear'].min(), df['TrainingTimesLastYear'].max()),\n",
        "    'PercentSalaryHike': (df['PercentSalaryHike'].min(), df['PercentSalaryHike'].max()),\n",
        "    'YearsSinceLastPromotion': (df['YearsSinceLastPromotion'].min(), df['YearsSinceLastPromotion'].max())\n",
        "}\n",
        "\n",
        "# Step 5: Test 100 Predictions Automatically (Insert this code)\n",
        "def generate_random_input_data(n=100):\n",
        "    monthly_income = np.random.randint(10000, 50000, size=n)\n",
        "    distance_from_home = np.random.uniform(1, 50, size=n)\n",
        "    training_times_last_year = np.random.randint(0, 5, size=n)\n",
        "    percent_salary_hike = np.random.uniform(1, 20, size=n)\n",
        "    years_since_last_promotion = np.random.randint(0, 10, size=n)\n",
        "\n",
        "    random_data = pd.DataFrame({\n",
        "        'MonthlyIncome': monthly_income,\n",
        "        'DistanceFromHome': distance_from_home,\n",
        "        'TrainingTimesLastYear': training_times_last_year,\n",
        "        'PercentSalaryHike': percent_salary_hike,\n",
        "        'YearsSinceLastPromotion': years_since_last_promotion\n",
        "    })\n",
        "\n",
        "    return random_data\n",
        "\n",
        "# Generate random test data\n",
        "test_data = generate_random_input_data(n=100)\n",
        "\n",
        "# Predict job satisfaction for each random test case\n",
        "predictions = best_rf.predict(test_data)\n",
        "\n",
        "# Convert numeric predictions to traffic light categories\n",
        "predicted_satisfaction = ['Green (Good)' if p == 4 else 'Yellow (Warning)' if p == 3 else 'Red (Bad)' for p in predictions]\n",
        "\n",
        "# Display the predictions\n",
        "results_df = test_data.copy()\n",
        "results_df['Predicted Job Satisfaction'] = predicted_satisfaction\n",
        "\n",
        "# Display a sample of 10 predictions to confirm\n",
        "print(results_df.head(30))"
      ],
      "metadata": {
        "id": "ff5AI16mxRYM",
        "outputId": "680e1488-38d7-4e3c-a988-a1ccd1c32a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "    MonthlyIncome  DistanceFromHome  TrainingTimesLastYear  PercentSalaryHike  \\\n",
            "0           37560         26.282469                      0          14.896613   \n",
            "1           10695         14.117487                      2          17.816064   \n",
            "2           20040         18.574513                      4           7.122351   \n",
            "3           46582         34.630625                      1          10.823829   \n",
            "4           34641         15.189968                      3           2.751249   \n",
            "5           15659         27.844356                      0          17.523972   \n",
            "6           33189         30.892725                      0           8.684546   \n",
            "7           36825          5.681684                      0          11.854513   \n",
            "8           31985          1.511244                      0          17.481258   \n",
            "9           42206         31.803394                      4           9.458067   \n",
            "10          31863         43.716529                      4          17.161525   \n",
            "11          48492         16.358699                      0          15.465237   \n",
            "12          37733          7.797802                      3           4.451030   \n",
            "13          33802          7.067616                      1           6.482626   \n",
            "14          49183         45.379495                      4           8.215546   \n",
            "15          47215         19.327774                      0          12.399834   \n",
            "16          30168         37.611284                      1          17.574823   \n",
            "17          25169          9.013567                      1          11.845533   \n",
            "18          19873         35.041407                      1           2.327315   \n",
            "19          49569         23.173005                      0          17.245949   \n",
            "20          14294         26.267613                      2           9.618623   \n",
            "21          35121         14.247044                      0           1.506513   \n",
            "22          39402         40.235917                      2          16.258533   \n",
            "23          35091         20.240085                      3          13.361796   \n",
            "24          27658         35.154923                      3          15.856478   \n",
            "25          13910         43.034290                      2          19.476043   \n",
            "26          42157         41.653183                      3          17.829001   \n",
            "27          17593         30.826371                      4           2.058383   \n",
            "28          25354         28.596726                      0          17.762248   \n",
            "29          31265         22.935260                      3           2.206613   \n",
            "\n",
            "    YearsSinceLastPromotion Predicted Job Satisfaction  \n",
            "0                         7               Green (Good)  \n",
            "1                         5               Green (Good)  \n",
            "2                         7               Green (Good)  \n",
            "3                         7               Green (Good)  \n",
            "4                         4               Green (Good)  \n",
            "5                         3           Yellow (Warning)  \n",
            "6                         1           Yellow (Warning)  \n",
            "7                         7               Green (Good)  \n",
            "8                         1               Green (Good)  \n",
            "9                         2               Green (Good)  \n",
            "10                        9           Yellow (Warning)  \n",
            "11                        3               Green (Good)  \n",
            "12                        3               Green (Good)  \n",
            "13                        1               Green (Good)  \n",
            "14                        7               Green (Good)  \n",
            "15                        4               Green (Good)  \n",
            "16                        7           Yellow (Warning)  \n",
            "17                        6               Green (Good)  \n",
            "18                        5           Yellow (Warning)  \n",
            "19                        9               Green (Good)  \n",
            "20                        2                  Red (Bad)  \n",
            "21                        9               Green (Good)  \n",
            "22                        5                  Red (Bad)  \n",
            "23                        1           Yellow (Warning)  \n",
            "24                        7           Yellow (Warning)  \n",
            "25                        0               Green (Good)  \n",
            "26                        6           Yellow (Warning)  \n",
            "27                        3           Yellow (Warning)  \n",
            "28                        1               Green (Good)  \n",
            "29                        7               Green (Good)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 2: Load your dataset (ensure this step has been completed before training)\n",
        "# df = pd.read_excel('/path/to/your/data.xlsx')  # Load the dataset from Excel\n",
        "# Process and prepare the data (already done earlier in your process)\n",
        "\n",
        "# Step 3: Train the Random Forest Model (if not already trained)\n",
        "#X = df[['MonthlyIncome', 'DistanceFromHome', 'TrainingTimesLastYear', 'PercentSalaryHike', 'YearsSinceLastPromotion']]\n",
        "#y = df['JobSatisfaction']  # Replace with your actual target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForest model\n",
        "best_rf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_leaf=1, min_samples_split=2, random_state=42)\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Grid Search for Hyperparameter Tuning (optional, already done earlier)\n",
        "# param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20, 30], ...}  # Define the grid\n",
        "# grid_search = GridSearchCV(estimator=best_rf, param_grid=param_grid, cv=5)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "# best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Step 5: Test 100 Predictions Automatically (Insert this code)\n",
        "def generate_random_input_data(n=100):\n",
        "    monthly_income = np.random.randint(10000, 50000, size=n)\n",
        "    distance_from_home = np.random.uniform(1, 50, size=n)\n",
        "    training_times_last_year = np.random.randint(0, 5, size=n)\n",
        "    percent_salary_hike = np.random.uniform(1, 20, size=n)\n",
        "    years_since_last_promotion = np.random.randint(0, 10, size=n)\n",
        "\n",
        "    random_data = pd.DataFrame({\n",
        "        'MonthlyIncome': monthly_income,\n",
        "        'DistanceFromHome': distance_from_home,\n",
        "        'TrainingTimesLastYear': training_times_last_year,\n",
        "        'PercentSalaryHike': percent_salary_hike,\n",
        "        'YearsSinceLastPromotion': years_since_last_promotion\n",
        "    })\n",
        "\n",
        "    return random_data\n",
        "\n",
        "# Generate random test data\n",
        "test_data = generate_random_input_data(n=100)\n",
        "\n",
        "# Predict job satisfaction for each random test case\n",
        "predictions = best_rf.predict(test_data)\n",
        "\n",
        "# Convert numeric predictions to traffic light categories\n",
        "predicted_satisfaction = ['Green (Good)' if p == 0 else 'Yellow (Warning)' if p == 1 else 'Red (Bad)' for p in predictions]\n",
        "\n",
        "# Display the predictions\n",
        "results_df = test_data.copy()\n",
        "results_df['Predicted Job Satisfaction'] = predicted_satisfaction\n",
        "\n",
        "# Display a sample of 10 predictions to confirm\n",
        "print(results_df.head(30))\n",
        "\n"
      ],
      "metadata": {
        "id": "mSd0P1inxERP",
        "outputId": "a678a94e-b7f4-49ef-bda1-12a1269ed68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d1ee2b333f58>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Initialize and train the RandomForest model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mbest_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mbest_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Step 4: Grid Search for Hyperparameter Tuning (optional, already done earlier)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1316\u001b[0m     )\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1065\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set file path\n",
        "file_path = '/content/drive/MyDrive/general_data.xlsx'\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "df = pd.read_excel(file_path)  # Use read_excel to load the default sheet\n",
        "\n",
        "# Filter out rows where Attrition is \"Yes\"\n",
        "df_filtered = df[df['Attrition'] == 'No'].copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df_cleaned = df_filtered.drop(columns=['Unnamed: 25', 'Unnamed: 26'], errors='ignore')\n",
        "\n",
        "# Select necessary features and target variable\n",
        "features = ['MonthlyIncome', 'DistanceFromHome', 'TrainingTimesLastYear',\n",
        "            'PercentSalaryHike', 'YearsSinceLastPromotion']\n",
        "target = 'JobSatisfaction'\n",
        "\n",
        "# Ensure the selected features and target exist in the dataset\n",
        "df_cleaned = df_cleaned[features + [target]].dropna()\n",
        "\n",
        "# Encode the target variable to categorical integers\n",
        "df_cleaned[target] = df_cleaned[target].astype(int)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features to ensure the model works optimally\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search for the best parameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")\n",
        "\n",
        "# Function to predict job satisfaction and map it to traffic light system\n",
        "def predict_job_satisfaction(monthly_income, distance_from_home, trainings_last_year,\n",
        "                              percent_salary_hike, years_since_last_promotion):\n",
        "    input_data = pd.DataFrame([{\n",
        "        'MonthlyIncome': monthly_income,\n",
        "        'DistanceFromHome': distance_from_home,\n",
        "        'TrainingTimesLastYear': trainings_last_year,\n",
        "        'PercentSalaryHike': percent_salary_hike,\n",
        "        'YearsSinceLastPromotion': years_since_last_promotion\n",
        "    }])\n",
        "\n",
        "    # Scale the input data\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    prediction = best_rf.predict(input_scaled)[0]  # Predict the satisfaction level (1-4)\n",
        "\n",
        "    # Map the prediction to traffic light system\n",
        "    if prediction >= 3:\n",
        "        return \"Green (Good)\"\n",
        "    elif prediction == 2:\n",
        "        return \"Yellow (Warning)\"\n",
        "    else:\n",
        "        return \"Red (Bad)\"\n",
        "\n",
        "# Automated threshold exploration\n",
        "def explore_thresholds():\n",
        "    # Define ranges for each input variable\n",
        "    income_range = np.linspace(10000, 50000, 10)  # Monthly income\n",
        "    distance_range = np.linspace(1, 50, 10)       # Distance from home\n",
        "    training_range = np.arange(0, 5)              # Training times last year\n",
        "    salary_hike_range = np.linspace(1, 20, 10)    # Percent salary hike\n",
        "    promotion_range = np.arange(0, 10)            # Years since last promotion\n",
        "\n",
        "    results = []  # Store predictions and corresponding inputs\n",
        "\n",
        "    # Iterate over all combinations of input values\n",
        "    for income in income_range:\n",
        "        for distance in distance_range:\n",
        "            for training in training_range:\n",
        "                for hike in salary_hike_range:\n",
        "                    for promotion in promotion_range:\n",
        "                        # Create input data\n",
        "                        prediction = predict_job_satisfaction(\n",
        "                            monthly_income=income,\n",
        "                            distance_from_home=distance,\n",
        "                            trainings_last_year=training,\n",
        "                            percent_salary_hike=hike,\n",
        "                            years_since_last_promotion=promotion\n",
        "                        )\n",
        "                        results.append({\n",
        "                            'MonthlyIncome': income,\n",
        "                            'DistanceFromHome': distance,\n",
        "                            'TrainingTimesLastYear': training,\n",
        "                            'PercentSalaryHike': hike,\n",
        "                            'YearsSinceLastPromotion': promotion,\n",
        "                            'Prediction': prediction\n",
        "                        })\n",
        "\n",
        "    # Convert results to DataFrame for analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "# Run the exploration\n",
        "thresholds_df = explore_thresholds()\n",
        "\n",
        "# Analyze the results\n",
        "print(\"Sample of Predictions:\")\n",
        "print(thresholds_df.head())\n",
        "\n",
        "# Group predictions to find ranges\n",
        "summary = thresholds_df.groupby('Prediction').agg({\n",
        "    'MonthlyIncome': ['min', 'max'],\n",
        "    'DistanceFromHome': ['min', 'max'],\n",
        "    'TrainingTimesLastYear': ['min', 'max'],\n",
        "    'PercentSalaryHike': ['min', 'max'],\n",
        "    'YearsSinceLastPromotion': ['min', 'max'],\n",
        "})\n",
        "\n",
        "print(\"\\nSummary of Ranges for Each Traffic Light Category:\")\n",
        "print(summary)\n",
        "\n",
        "# Interactive Input (for testing individual cases)\n",
        "monthly_income = int(input(\"Enter Monthly Income: \"))\n",
        "distance_from_home = int(input(\"Enter Distance From Home (in km): \"))\n",
        "trainings_last_year = int(input(\"Enter Training Times Last Year: \"))\n",
        "percent_salary_hike = int(input(\"Enter Percent Salary Hike: \"))\n",
        "years_since_last_promotion = int(input(\"Enter Years Since Last Promotion: \"))\n",
        "\n",
        "# Get the prediction\n",
        "result = predict_job_satisfaction(monthly_income, distance_from_home,\n",
        "                                   trainings_last_year, percent_salary_hike,\n",
        "                                   years_since_last_promotion)\n",
        "print(f\"\\nPredicted Job Satisfaction: {result}\")\n"
      ],
      "metadata": {
        "id": "NYTTJ-2poCZV",
        "outputId": "a6519780-2a69-48ca-fab4-abe12cc15c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dbc44c9fad5d>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Perform grid search for the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}